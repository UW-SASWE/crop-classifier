{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "##### Functions #####\n",
    "#####################\n",
    "\n",
    "#Function to convert from dB\n",
    "def toNatural(img):\n",
    "    return ee.Image(10.0).pow(img.select(0).divide(10.0))\n",
    "\n",
    "# Function to convert to dB\n",
    "def toDB(img):\n",
    "    return ee.Image(img).log10().multiply(10.0)\n",
    "\n",
    "#Apllying a Refined Lee Speckle filter as coded in the SNAP 3.0 S1TBX:\n",
    "#https:#github.com/senbox-org/s1tbx/blob/master/s1tbx-op-sar-processing/src/main/java/org/esa/s1tbx/sar/gpf/filtering/SpeckleFilters/RefinedLee.java\n",
    "def RefinedLee(img):\n",
    "  # img must be in natural units, i.e. not in dB!\n",
    "    # Set up 3x3 kernels\n",
    "\n",
    "    # convert to natural.. do not apply function on dB!\n",
    "    myimg = toNatural(img)\n",
    "\n",
    "    weights3 = ee.List.repeat(ee.List.repeat(1,3),3)\n",
    "    kernel3 = ee.Kernel.fixed(3,3, weights3, 1, 1, False)\n",
    "\n",
    "    mean3 = myimg.reduceNeighborhood(ee.Reducer.mean(), kernel3)\n",
    "    variance3 = myimg.reduceNeighborhood(ee.Reducer.variance(), kernel3)\n",
    "\n",
    "    # Use a sample of the 3x3 windows inside a 7x7 windows to determine gradients and directions\n",
    "    sample_weights = ee.List([[0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0], [0,1,0,1,0,1,0], [0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0]])\n",
    "\n",
    "    sample_kernel = ee.Kernel.fixed(7,7, sample_weights, 3,3, False)\n",
    "\n",
    "    # Calculate mean and variance for the sampled windows and store as 9 bands\n",
    "    sample_mean = mean3.neighborhoodToBands(sample_kernel)\n",
    "    sample_var = variance3.neighborhoodToBands(sample_kernel)\n",
    "\n",
    "    # Determine the 4 gradients for the sampled windows\n",
    "    gradients = sample_mean.select(1).subtract(sample_mean.select(7)).abs()\n",
    "    gradients = gradients.addBands(sample_mean.select(6).subtract(sample_mean.select(2)).abs())\n",
    "    gradients = gradients.addBands(sample_mean.select(3).subtract(sample_mean.select(5)).abs())\n",
    "    gradients = gradients.addBands(sample_mean.select(0).subtract(sample_mean.select(8)).abs())\n",
    "\n",
    "    # And find the maximum gradient amongst gradient bands\n",
    "    max_gradient = gradients.reduce(ee.Reducer.max())\n",
    "\n",
    "    # Create a mask for band pixels that are the maximum gradient\n",
    "    gradmask = gradients.eq(max_gradient)\n",
    "\n",
    "    # duplicate gradmask bands: each gradient represents 2 directions\n",
    "    gradmask = gradmask.addBands(gradmask)\n",
    "\n",
    "    # Determine the 8 directions\n",
    "    directions = sample_mean.select(1).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(7))).multiply(1)\n",
    "    directions = directions.addBands(sample_mean.select(6).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(2))).multiply(2))\n",
    "    directions = directions.addBands(sample_mean.select(3).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(5))).multiply(3))\n",
    "    directions = directions.addBands(sample_mean.select(0).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(8))).multiply(4))\n",
    "    # The next 4 are the not() of the previous 4\n",
    "    directions = directions.addBands(directions.select(0).Not().multiply(5))\n",
    "    directions = directions.addBands(directions.select(1).Not().multiply(6))\n",
    "    directions = directions.addBands(directions.select(2).Not().multiply(7))\n",
    "    directions = directions.addBands(directions.select(3).Not().multiply(8))\n",
    "\n",
    "    # Mask all values that are not 1-8\n",
    "    directions = directions.updateMask(gradmask)\n",
    "\n",
    "    # \"collapse\" the stack into a singe band image (due to masking, each pixel has just one value (1-8) in it's directional band, and is otherwise masked)\n",
    "    directions = directions.reduce(ee.Reducer.sum())\n",
    "\n",
    "    sample_stats = sample_var.divide(sample_mean.multiply(sample_mean))\n",
    "\n",
    "    # Calculate localNoiseVariance\n",
    "    sigmaV = sample_stats.toArray().arraySort().arraySlice(0,0,5).arrayReduce(ee.Reducer.mean(), [0])\n",
    "\n",
    "    # Set up the 7*7 kernels for directional statistics\n",
    "    rect_weights = ee.List.repeat(ee.List.repeat(0,7),3).cat(ee.List.repeat(ee.List.repeat(1,7),4))\n",
    "\n",
    "    diag_weights = ee.List([[1,0,0,0,0,0,0], [1,1,0,0,0,0,0], [1,1,1,0,0,0,0],\n",
    "    [1,1,1,1,0,0,0], [1,1,1,1,1,0,0], [1,1,1,1,1,1,0], [1,1,1,1,1,1,1]])\n",
    "\n",
    "    rect_kernel = ee.Kernel.fixed(7,7, rect_weights, 3, 3, False)\n",
    "    diag_kernel = ee.Kernel.fixed(7,7, diag_weights, 3, 3, False)\n",
    "\n",
    "    # Create stacks for mean and variance using the original kernels. Mask with relevant direction.\n",
    "    dir_mean = myimg.reduceNeighborhood(ee.Reducer.mean(), rect_kernel).updateMask(directions.eq(1))\n",
    "    dir_var = myimg.reduceNeighborhood(ee.Reducer.variance(), rect_kernel).updateMask(directions.eq(1))\n",
    "\n",
    "    dir_mean = dir_mean.addBands(myimg.reduceNeighborhood(ee.Reducer.mean(), diag_kernel).updateMask(directions.eq(2)))\n",
    "    dir_= dir_var.addBands(myimg.reduceNeighborhood(ee.Reducer.variance(), diag_kernel).updateMask(directions.eq(2)))\n",
    "\n",
    "    # and add the bands for rotated kernels\n",
    "    for i in range(1, 4):\n",
    "        dir_mean = dir_mean.addBands(myimg.reduceNeighborhood(ee.Reducer.mean(), rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)))\n",
    "        dir_= dir_var.addBands(myimg.reduceNeighborhood(ee.Reducer.variance(), rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)))\n",
    "        dir_mean = dir_mean.addBands(myimg.reduceNeighborhood(ee.Reducer.mean(), diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)))\n",
    "        dir_= dir_var.addBands(myimg.reduceNeighborhood(ee.Reducer.variance(), diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)))\n",
    "\n",
    "    # \"collapse\" the stack into a single band image (due to masking, each pixel has just one value in it's directional band, and is otherwise masked)\n",
    "    dir_mean = dir_mean.reduce(ee.Reducer.sum())\n",
    "    dir_= dir_var.reduce(ee.Reducer.sum())\n",
    "\n",
    "    # A finally generate the filtered value\n",
    "    varX = dir_var.subtract(dir_mean.multiply(dir_mean).multiply(sigmaV)).divide(sigmaV.add(1.0))\n",
    "\n",
    "    b = varX.divide(dir_var)\n",
    "\n",
    "    result = dir_mean.add(b.multiply(myimg.subtract(dir_mean)))\n",
    "    #return(result)\n",
    "    return(img.select([]).addBands(ee.Image(toDB(result.arrayGet(0))).rename(\"VH\")))\n",
    "\n",
    "def bufferPoly(feature):\n",
    "    return feature#.buffer(20);   # substitute in your value of Z here\n",
    "\n",
    "# classifyCrop()\n",
    "##### main #####\n",
    "\n",
    "def classifyCrop(\n",
    "    datacrop_combined,\n",
    "    bdForests,\n",
    "    seasonDict,\n",
    "    roi,\n",
    "    Map, # geemap.map object\n",
    "    inpDate_Start=2021,\n",
    "    seasonSelect='Aman (Aug-Dec)'\n",
    "    ):\n",
    "    # startdate = startdate = ee.Date.fromYMD(inpDate_Start.getValue()-1,12,1)\n",
    "    # enddate   = ee.Date.fromYMD(inpDate_Start.getValue()-0,11,25)\n",
    "    startdate = startdate = ee.Date.fromYMD(inpDate_Start-1,12,1)\n",
    "    enddate   = ee.Date.fromYMD(inpDate_Start-0,11,25)\n",
    "\n",
    "    # TODO: Work on these later when the GUI components are added.\n",
    "    # maplabel.setValue('Rice Classified Map') # for ' + ee.Date(enddate).format('YYYY-MM').getInfo())\n",
    "    # presultsLabel.setValue('')\n",
    "\n",
    "    # col = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "    #             .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')) \\\n",
    "    #             .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
    "    #             .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    "    #             .filterBounds(BGD) \\\n",
    "    #             .filterDate(startdate,enddate) \\\n",
    "    #             .select(['VH']) \\\n",
    "    #             .map(RefinedLee)\n",
    "\n",
    "    col = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "                .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')) \\\n",
    "                .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
    "                .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    "                .filterBounds(roi) \\\n",
    "                .filterDate(startdate,enddate) \\\n",
    "                .select(['VH']) \\\n",
    "                .map(RefinedLee)\n",
    "\n",
    "    # create monthly time series\n",
    "    monList = ee.List.sequence(1,11,1)#.aside(print,'month')\n",
    "    def monthlyComposite(month):\n",
    "        # year = inpDate_Start.getValue()-0\n",
    "        year = inpDate_Start-0\n",
    "        start = ee.Date.fromYMD(year,month,1)\n",
    "        end = start.advance(1,\"month\")\n",
    "        S1 = col.filterDate(start,end).max()\n",
    "        return S1\n",
    "\n",
    "    s1Collection = ee.ImageCollection(monList.map(monthlyComposite))#.aside(print,'S1 collection')\n",
    "    compositedImage = ee.Image(s1Collection.toList(11).get(0))#Collection\n",
    "    for i in range(1,11):\n",
    "        compositedImage = compositedImage.addBands(ee.Image(s1Collection.toList(11).get(i)).select([0]))\n",
    "\n",
    "    # mask forests\n",
    "    def maskInside(image, geometry):\n",
    "        mask = ee.Image.constant(1).clip(geometry).mask().Not()\n",
    "        return image.updateMask(mask)\n",
    "        \n",
    "    compositedImage = maskInside(compositedImage, bdForests)\n",
    "\n",
    "    compositeBoro = compositedImage.select(seasonDict[seasonSelect]['months'])#.clip(BGD);# Boro rice(Jan-April)\n",
    "    compositeAus = compositeBoro#compositedImage.select([4,5,6])#.clip(SA);# Aus rice(May-July)\n",
    "    compositeAman = compositeBoro#compositedImage.select([7,8,9,10])# ,11].clip(SA);# Aman rice (Aug-Dec)\n",
    "\n",
    "    #merge, buffer features and pickup random samples for training & validation\n",
    "    fcBoro = datacrop_combined; #waterBoro.merge(vegetation).merge(Builtup).merge(paddyBoro)\n",
    "    fcAus = fcBoro#waterBoro.merge(vegetation).merge(Builtup).merge(paddyAus)\n",
    "    fcAman = fcBoro#waterBoro.merge(vegetation).merge(Builtup).merge(paddyAman)\n",
    "\n",
    "    buffered_fcBoro = fcBoro.map(bufferPoly)\n",
    "    buffered_fcAus = fcAus.map(bufferPoly)\n",
    "    buffered_fcAman = fcAman.map(bufferPoly)\n",
    "\n",
    "    #Assign random numbers for a test/train split\n",
    "    fcBoro = buffered_fcBoro.randomColumn('random',2015)\n",
    "    fcAus = buffered_fcAus.randomColumn('random',2015)\n",
    "    fcAman = buffered_fcAman.randomColumn('random',2015)\n",
    "\n",
    "    #create training data\n",
    "    #Join training samples with bands\n",
    "    bandsBoro = seasonDict[seasonSelect]['bands'] #['VH','VH_1','VH_2','VH_3'];#Boro season\n",
    "    bandsAus = bandsBoro#['VH_4','VH_5','VH_6'];#Aus season\n",
    "    bandsAman = bandsBoro#['VH_7','VH_8','VH_9','VH_10']; #,'VH_11'];#Aman season\n",
    "\n",
    "    trainingBoro = compositeBoro.select(bandsBoro).sampleRegions(\n",
    "        collection=fcBoro,\n",
    "        properties=['class','random'],\n",
    "        scale=500\n",
    "        )\n",
    "    trainingAus = compositeAus.select(bandsAus).sampleRegions(\n",
    "        collection=fcAus,\n",
    "        properties=['class','random'],\n",
    "        scale=500\n",
    "        )\n",
    "    trainingAman = compositeAman.select(bandsAman).sampleRegions(\n",
    "        collection=fcAman,\n",
    "        properties=['class','random'],\n",
    "        scale=500\n",
    "        )\n",
    "\n",
    "    # # # # #split the training and testing ROI into a 30/70 percent\n",
    "    trainingAccuracyBoro = trainingBoro.filterMetadata('random','less_than', 0.7)\n",
    "    trainingAccuracyAus = trainingAus.filterMetadata('random','less_than', 0.7)\n",
    "    trainingAccuracyAman = trainingAman.filterMetadata('random','less_than', 0.7)\n",
    "\n",
    "    testingAccuracyBoro = trainingBoro.filterMetadata('random','not_less_than', 0.7)\n",
    "    testingAccuracyAus = trainingAus.filterMetadata('random','not_less_than', 0.7)\n",
    "    testingAccuracyAman = trainingAman.filterMetadata('random','not_less_than', 0.7)\n",
    "\n",
    "    # Train the classifier\n",
    "    trainingClassifierBoro = ee.Classifier.smileRandomForest(10).train(\n",
    "        features=trainingAccuracyBoro,\n",
    "        classProperty='class',\n",
    "        inputProperties=bandsBoro\n",
    "        )\n",
    "    trainingClassifierAus = ee.Classifier.smileRandomForest(10).train(\n",
    "        features=trainingAccuracyAus,\n",
    "        classProperty='class',\n",
    "        inputProperties=bandsAus\n",
    "        )\n",
    "    trainingClassifierAman = ee.Classifier.smileRandomForest(10).train(\n",
    "        features=trainingAccuracyAman,\n",
    "        classProperty='class',\n",
    "        inputProperties=bandsAman\n",
    "        )\n",
    "\n",
    "    # Classify rice and others on the composited images\n",
    "    classifiedBoro = compositeBoro.select(bandsBoro).classify(trainingClassifierBoro)\n",
    "    classifiedAus = compositeAus.select(bandsAus).classify(trainingClassifierAus)\n",
    "    classifiedAman = compositeAman.select(bandsAman).classify(trainingClassifierAman)\n",
    "\n",
    "    #accuracy assessment\n",
    "    validationBoro = testingAccuracyBoro.classify(trainingClassifierBoro)\n",
    "    validationAus = testingAccuracyAus.classify(trainingClassifierAus)\n",
    "    validationAman = testingAccuracyAman.classify(trainingClassifierAman)\n",
    "\n",
    "    errorMatrixBoro = validationBoro.errorMatrix('class','classification')\n",
    "    errorMatrixAus = validationAus.errorMatrix('class','classification')\n",
    "    errorMatrixAman = validationAman.errorMatrix('class','classification')\n",
    "    \n",
    "    print('Accuracy',errorMatrixAman.accuracy())\n",
    "\n",
    "    classVis = {'min': 0, 'max': 1, 'palette': ['484848','f2c649']}\n",
    "\n",
    "    # Map.addLayer(classifiedAman.clip(BGD),classVis, 'classified')\n",
    "    Map.addLayer(classifiedAman.clip(roi), classVis, 'classified')\n",
    "    print('check')\n",
    "    # calculate area\n",
    "    areaImage = ee.Image.pixelArea().addBands(classifiedAman)\n",
    "    areas = areaImage.reduceRegion(\n",
    "        reducer=ee.Reducer.sum().group(\n",
    "            groupField=1,\n",
    "            groupName='class',\n",
    "            ),\n",
    "        # 'geometry': BGD.geometry(),\n",
    "        geometry=roi.geometry(),\n",
    "        scale=500,\n",
    "        maxPixels=1e13,\n",
    "        tileScale=8\n",
    "        )\n",
    "\n",
    "    # Print the area calculations.\n",
    "    print('##### CLASS AREA SQ. METERS (RF) #####')\n",
    "    arobj = ee.List(areas.get('groups')).get(1)\n",
    "    arval =  ee.Number(ee.Dictionary(arobj).get('sum')).divide(1e10)\n",
    "    print(arval)\n",
    "\n",
    "    strArea = ee.String(ee.Number.parse(arval.format('%.2f')))\n",
    "\n",
    "    resultString = ee.String('>> Rice Classified Area: ').cat(strArea).cat(ee.String(' mn hectares'))\n",
    "\n",
    "    # presultsLabel.setValue('Computing, please wait...')\n",
    "    # resultString.evaluate(function(val){presultsLabel.setValue(val)})\n",
    "    print('Computing, please wait...')\n",
    "    presultsLabel = resultString\n",
    "\n",
    "    # panel.remove(presultsLabel)\n",
    "    # panel.add(presultsLabel)\n",
    "    print(presultsLabel)\n",
    "\n",
    "    # export accuracy to Google Drive\n",
    "    ee.batch.Export.image.toDrive(\n",
    "        crs='EPSG:4326',\n",
    "        # 'image': classifiedAman.clip(BGD).multiply(100).uint8(),\n",
    "        image=classifiedAman.clip(roi).multiply(100).uint8(),\n",
    "        description=\"Aman_R1_SA_NE\",\n",
    "        scale=10,\n",
    "        # 'region': BGD,\n",
    "        region=roi,\n",
    "        maxPixels=10000000000000\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb8ebe179a34d06917f2d6b7c28f72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variables\n",
    "# Districts BGD\n",
    "BGD = ee.FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\").filterMetadata('country_co', 'equals', 'BG')\n",
    "datacrop_combined = ee.FeatureCollection('users/climateClass/BD_rice/datacrop_combined')\n",
    "bdForests = ee.FeatureCollection('users/climateClass/BD_rice/bgd_phy_forestnaturalparks_lged')\n",
    "seasonDict = {\n",
    "    'Boro (Jan-Apr)': {'months':[0,1,2,3], 'bands':['VH','VH_1','VH_2','VH_3']},\n",
    "    'Aus (May-Jul)': {'months':[4,5,6], 'bands':['VH_4','VH_5','VH_6']},\n",
    "    'Aman (Aug-Dec)': {'months':[7,8,9,10], 'bands':['VH_7','VH_8','VH_9','VH_10']}\n",
    "    }\n",
    "roi = BGD\n",
    "\n",
    "inpDate_Start=2021\n",
    "seasonSelect='Aman (Aug-Dec)'\n",
    "Map = geemap.Map()\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map = geemap.Map()\n",
    "Map.addLayer(BGD, {}, 'Boundary')\n",
    "Map.centerObject(BGD,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy "
     ]
    }
   ],
   "source": [
    "classifyCrop(\n",
    "    datacrop_combined=datacrop_combined,\n",
    "    bdForests=bdForests,\n",
    "    seasonDict=seasonDict,\n",
    "    roi=roi,\n",
    "    Map=Map, # geemap.map object\n",
    "    inpDate_Start=2021,\n",
    "    seasonSelect='Aman (Aug-Dec)'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('crop-classifier')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ce96077555c9ba1ca58c7c68208d1eef6976e7f90dc0e8409a5c0e71158a348"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
